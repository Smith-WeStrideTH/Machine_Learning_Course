{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a79824",
   "metadata": {},
   "source": [
    "# ภารกิจเสริม: การถดถอยเชิงเส้นหลายตัวแปร\n",
    "ในห้องปฏิบัติการนี้ คุณจะขยายโครงสร้างข้อมูลและขั้นตอนที่พัฒนาขึ้นก่อนหน้านี้เพื่อรองรับหลายคุณลักษณะ ขั้นตอนหลายอย่างได้รับการปรับปรุง ทำให้ห้องปฏิบัติการยาวขึ้น แต่มีการปรับเปลี่ยนเล็กน้อยในขั้นตอนก่อนหน้านี้ ทำให้สามารถตรวจสอบได้อย่างรวดเร็ว\n",
    "\n",
    "\n",
    "# เนื้อหา\n",
    "- [&nbsp;&nbsp;1.1 เป้าหมาย](#toc_15456_1.1)\n",
    "- [&nbsp;&nbsp;1.2 เครื่องมือ](#toc_15456_1.2)\n",
    "- [&nbsp;&nbsp;1.3  สัญลักษณ์](#toc_15456_1.3)\n",
    "- [2 ปัญหา](#toc_15456_2)\n",
    "- [&nbsp;&nbsp;2.1 เมทริกซ์ X ที่มีตัวอย่างของเรา](#toc_15456_2.1)\n",
    "- [&nbsp;&nbsp;2.2 เวกเตอร์พารามิเตอร์ w, b](#toc_15456_2.2)\n",
    "- [3 การทำนายแบบจำลองด้วยตัวแปรหลายตัว](#toc_15456_3)\n",
    "- [&nbsp;&nbsp;3.1 องค์ประกอบการทำนายเดี่ยวตามองค์ประกอบ](#toc_15456_3.1)\n",
    "- [&nbsp;&nbsp;3.2 การทำนายเดี่ยว เวกเตอร์](#toc_15456_3.2)\n",
    "- [4 คำนวณ cost ด้วยตัวแปรหลายตัว](#toc_15456_4)\n",
    "- [5 Gradient Descent การไล่ระดับลงด้วยตัวแปรหลายตัว](#toc_15456_5)\n",
    "- [&nbsp;&nbsp;5.1 คำนวณการไล่ระดับด้วยตัวแปรหลายตัว](#toc_15456_5.1)\n",
    "- [&nbsp;&nbsp;5.2 Gradient Descent การไล่ระดับลงด้วยตัวแปรหลายตัว](#toc_15456_5.2)\n",
    "- [6 ยินดีด้วย](#toc_15456_6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe95e31c",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_1.1\"></a>\n",
    "## 1.1 เป้าหมาย\n",
    "- ขยายขั้นตอนการถดถอยของเราเพื่อรองรับคุณลักษณะหลายอย่าง\n",
    "   - ขยายโครงสร้างข้อมูลเพื่อรองรับคุณลักษณะหลายอย่าง\n",
    "   - เขียนโปรแกรมทำนาย ต้นทุน และการไล่ระดับใหม่เพื่อรองรับคุณลักษณะหลายอย่าง\n",
    "   - ใช้ np.dot ของ NumPy เพื่อเวคเตอร์การใช้งานเพื่อความเร็วและความเรียบง่าย"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023314c3",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_1.2\"></a>\n",
    "## 1.2 เครื่องมือ\n",
    "ในห้องปฏิบัติการนี้ เราจะใช้:\n",
    "- NumPy ซึ่งเป็นไลบรารีที่นิยมสำหรับการคำนวณทางวิทยาศาสตร์\n",
    "- Matplotlib ซึ่งเป็นไลบรารีที่นิยมสำหรับการพล็อตข้อมูล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65062ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: import requsts and download from this github link : https://raw.githubusercontent.com/Smith-WeStrideTH/Machine_Learning_Course/main/work/deeplearning.mplstyle\n",
    "\n",
    "import requests\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/Smith-WeStrideTH/Machine_Learning_Course/main/work/deeplearning.mplstyle'\n",
    "response = requests.get(url)\n",
    "\n",
    "with open('deeplearning.mplstyle', 'wb') as f:\n",
    "  f.write(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd53133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "np.set_printoptions(precision=2)  # reduced display precision on numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57805d6",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_1.3\"></a>\n",
    "## 1.3 Notation(สัญลักษณ์)\n",
    "นี่คือสรุปสัญลักษณ์บางส่วนที่คุณจะพบ ซึ่งได้รับการอัปเดตสำหรับคุณลักษณะหลายรายการ:\n",
    "\n",
    "|General <img width=70/> <br />  Notation  <img width=70/> | Description<img width=350/>| Python (if applicable) |\n",
    "|: ------------|: ------------------------------------------------------------||\n",
    "| $a$ | สเกลาร์ ไม่เป็นตัวหนา                                                      ||\n",
    "| $\\mathbf{a}$ | เวกเตอร์ ตัวหนา                                                 ||\n",
    "| $\\mathbf{A}$ | เมทริกซ์ ตัวหนาอักษรใหญ่                                         ||\n",
    "| **การถดถอย (Regression)** |         |    |     |\n",
    "|  $\\mathbf{X}$ | เมทริกซ์ตัวอย่างฝึกอบรม                  | `X_train` |   \n",
    "|  $\\mathbf{y}$  | เป้าหมายตัวอย่างฝึกอบรม                | `y_train` \n",
    "|  $\\mathbf{x}^{(i)}$, $y^{(i)}$ | $i_{th}$ตัวอย่างการฝึกอบรม | `X[i]`, `y[i]`|\n",
    "| m | จำนวนตัวอย่างการฝึกอบรม | `m`|\n",
    "| n | จำนวนคุณลักษณะในแต่ละตัวอย่าง | `n`|\n",
    "|  $\\mathbf{w}$  |  พารามิเตอร์: น้ำหนัก (weight),                       | `w`    |\n",
    "|  $b$           |  พารามิเตอร์: อคติ (bias)                                           | `b`    |     \n",
    "| $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ | ผลลัพธ์ของการประเมินแบบจำลองที่  $\\mathbf{x^{(i)}}$ โดยมีพารามิเตอร์ $\\mathbf{w},b$: $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)}+b$  | `f_wb` | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2564db4c",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_2\"></a>\n",
    "# 2 ปัญหา\n",
    "\n",
    "คุณจะใช้ตัวอย่างการกระตุ้นของการทำนายราคาบ้าน ชุดข้อมูลการฝึกอบรมประกอบด้วยสามตัวอย่างที่มีสี่คุณลักษณะ (ขนาด, ห้องนอน, ชั้น และอายุ) ตามที่แสดงในตารางด้านล่าง โปรดทราบว่า ไม่เหมือนกับห้องปฏิบัติการก่อนหน้านี้ ขนาดเป็นตารางฟุต ไม่ใช่ 1000 ตารางฟุต ซึ่งทำให้เกิดปัญหาที่คุณจะแก้ไขได้ในห้องปฏิบัติการถัดไป!\n",
    "\n",
    "| Size (sqft) | Number of Bedrooms  | Number of floors | Age of  Home | Price (1000s dollars)  |   \n",
    "| ----------------| ------------------- |----------------- |--------------|-------------- |  \n",
    "| 2104            | 5                   | 1                | 45           | 460           |  \n",
    "| 1416            | 3                   | 2                | 40           | 232           |  \n",
    "| 852             | 2                   | 1                | 35           | 178           |  \n",
    "\n",
    "คุณจะสร้างแบบจำลองการถดถอยเชิงเส้นโดยใช้ค่าเหล่านี้เพื่อที่คุณจะสามารถทำนายราคาสำหรับบ้านอื่น ๆ ได้ ตัวอย่างเช่น บ้านขนาด 1200 ตารางฟุต มี 3 ห้องนอน 1 ชั้น อายุ 40 ปี\n",
    "\n",
    "โปรดเรียกใช้เซลล์โค้ดต่อไปนี้เพื่อสร้างตัวแปร `X_train` และ `y_train` ของคุณ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b91c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y_train = np.array([460, 232, 178])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84a4d65",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_2.1\"></a>\n",
    "## 2.1 เมทริกซ์ X ที่มีตัวอย่างของเรา\n",
    "คล้ายกับตารางด้านบน ตัวอย่างจะถูกเก็บในเมทริกซ์ NumPy `X_train` แต่ละแถวของเมทริกซ์แทนตัวอย่างหนึ่งตัว เมื่อคุณมีตัวอย่างการฝึก $m$ ตัว ($m$ คือสามในตัวอย่างของเรา) และมีคุณลักษณะ $n$ ตัว (สี่ในตัวอย่างของเรา) $\\mathbf{X}$  คือเมทริกซ์ที่มีมิติ ($m$, $n$) (m แถว n คอลัมน์)\n",
    "\n",
    "$$\\mathbf{X} = \n",
    "\\begin{pmatrix}\n",
    " x^{(0)}_0 & x^{(0)}_1 & \\cdots & x^{(0)}_{n-1} \\\\ \n",
    " x^{(1)}_0 & x^{(1)}_1 & \\cdots & x^{(1)}_{n-1} \\\\\n",
    " \\cdots \\\\\n",
    " x^{(m-1)}_0 & x^{(m-1)}_1 & \\cdots & x^{(m-1)}_{n-1} \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "สัญลักษณ์:\n",
    "- $\\mathbf{x}^{(i)}$ คือเวกเตอร์ที่มีตัวอย่างที่ i. $\\mathbf{x}^{(i)}$ $ = (x^{(i)}_0, x^{(i)}_1, \\cdots,x^{(i)}_{n-1})$\n",
    "- $x^{(i)}_j$ คือองค์ประกอบที่ j ในตัวอย่างที่ i อักษรย่อในวงเล็บบ่งชี้หมายเลขตัวอย่างในขณะที่ตัวห้อยแสดงถึงองค์ประกอบ  \n",
    "\n",
    "แสดงข้อมูลอินพุต\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d2d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is stored in numpy array/matrix\n",
    "print(f\"X Shape: {X_train.shape}, X Type:{type(X_train)})\")\n",
    "print(X_train)\n",
    "print(f\"y Shape: {y_train.shape}, y Type:{type(y_train)})\")\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabd244e",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_2.2\"></a>\n",
    "\n",
    "## 2.2 เวกเตอร์พารามิเตอร์ w, b\n",
    "\n",
    "* $\\mathbf{w}$ เป็นเวกเตอร์ที่มี $n$ องค์ประกอบ\n",
    "- แต่ละองค์ประกอบมีพารามิเตอร์ที่เกี่ยวข้องกับหนึ่งคุณลักษณะ\n",
    "- ในชุดข้อมูลของเรา n คือ 4\n",
    "- โดยนัย เราวาดสิ่งนี้เป็นเวกเตอร์คอลัมน์\n",
    "$$\\mathbf{w} = \\begin{pmatrix}\n",
    "w_0 \\\\ \n",
    "w_1 \\\\\n",
    "\\cdots\\\\\n",
    "w_{n-1}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "* $b$ เป็นพารามิเตอร์สเกลาร์  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acb3af5",
   "metadata": {},
   "source": [
    "เพื่อการสาธิต $\\mathbf{w}$ และ $b$ จะถูกโหลดด้วยค่าที่เลือกเริ่มต้นบางค่าที่ใกล้เคียงกับค่าที่เหมาะสมที่สุด $\\mathbf{w}$ เป็นเวกเตอร์ NumPy 1 มิติ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b6dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_init = 785.1811367994083\n",
    "w_init = np.array([ 0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
    "print(f\"w_init shape: {w_init.shape}, b_init type: {type(b_init)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c21d05",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_3\"></a>\n",
    "# 3 3 การทำนายแบบจำลองด้วยตัวแปรหลายตัว\n",
    "การทำนายของแบบจำลองด้วยตัวแปรหลายตัวจะถูกกำหนดโดยแบบจำลองเชิงเส้น:\n",
    "\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) =  w_0x_0 + w_1x_1 +... + w_{n-1}x_{n-1} + b \\tag{1}$$\n",
    "หรือในสัญกรณ์เวกเตอร์:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) = \\mathbf{w} \\cdot \\mathbf{x} + b  \\tag{2} $$ \n",
    "โดยที่  $\\cdot$  คือ `ผลคูณดอท` ของเวกเตอร์\n",
    "\n",
    "เพื่อแสดงผลคูณดอท เราจะนำการทำนายไปใช้งานโดยใช้ (1) และ (2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d27994a",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_3.1\"></a>\n",
    "## 3.1 การทำนายเดี่ยว องค์ประกอบตามองค์ประกอบ\n",
    "การทำนายก่อนหน้านี้ของเราคูณค่าคุณลักษณะหนึ่งด้วยพารามิเตอร์หนึ่งและบวกพารามิเตอร์อคติ การขยายโดยตรงของการนำไปใช้ก่อนหน้านี้ของการทำนายไปยังคุณลักษณะหลายตัวจะเป็นการนำไปใช้ (1) ด้านบนโดยใช้ลูปเหนือแต่ละองค์ประกอบ ทำการคูณด้วยพารามิเตอร์ของมันแล้วบวกพารามิเตอร์อคติในตอนท้าย\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78ff4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_loop(x, w, b): \n",
    "    \"\"\"\n",
    "    single predict using linear regression\n",
    "    \n",
    "    Args:\n",
    "      x (ndarray): Shape (n,) example with multiple features\n",
    "      w (ndarray): Shape (n,) model parameters    \n",
    "      b (scalar):  model parameter     \n",
    "      \n",
    "    Returns:\n",
    "      p (scalar):  prediction\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    p = 0\n",
    "    for i in range(n):\n",
    "        p_i = x[i] * w[i]  \n",
    "        p = p + p_i         \n",
    "    p = p + b                \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c964d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a row from our training data\n",
    "x_vec = X_train[0,:]\n",
    "print(f\"x_vec shape {x_vec.shape}, x_vec value: {x_vec}\")\n",
    "\n",
    "# make a prediction\n",
    "f_wb = predict_single_loop(x_vec, w_init, b_init)\n",
    "print(f\"f_wb shape {f_wb.shape}, prediction: {f_wb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41257af6",
   "metadata": {},
   "source": [
    "หมายเหตุรูปร่าง(shape)ของ `x_vec`\n",
    "\n",
    "`x_vec` เป็นเวกเตอร์ NumPy 1 มิติที่มี 4 องค์ประกอบ (4,) ผลลัพธ์ `f_wb` เป็นสเกลาร์\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c9f212",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_3.2\"></a>\n",
    "## 3.2 การทำนายเดี่ยว, เวกเตอร์\n",
    "\n",
    "เนื่องจากสมการ (1) ด้านบนสามารถนำไปใช้โดยใช้ผลคูณจุดดังเช่น (2) ด้านบน เราสามารถใช้ประโยชน์จากการดำเนินการของเวกเตอร์เพื่อเร่งการทำนาย\n",
    "\n",
    "จำไว้จากแลป Python/Numpy ว่า `np.dot()`[[link](https://numpy.org/doc/stable/reference/generated/numpy.dot.html)] สามารถใช้เพื่อคำนวณผลคูณจุดของเวกเตอร์\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50d007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, w, b): \n",
    "    \"\"\"\n",
    "    single predict using linear regression\n",
    "    Args:\n",
    "      x (ndarray): Shape (n,) example with multiple features\n",
    "      w (ndarray): Shape (n,) model parameters   \n",
    "      b (scalar):             model parameter \n",
    "      \n",
    "    Returns:\n",
    "      p (scalar):  prediction\n",
    "    \"\"\"\n",
    "    p = np.dot(x, w) + b     \n",
    "    return p    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823fb990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a row from our training data\n",
    "x_vec = X_train[0,:]\n",
    "print(f\"x_vec shape {x_vec.shape}, x_vec value: {x_vec}\")\n",
    "\n",
    "# make a prediction\n",
    "f_wb = predict(x_vec,w_init, b_init)\n",
    "print(f\"f_wb shape {f_wb.shape}, prediction: {f_wb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf62ae5",
   "metadata": {},
   "source": [
    "ผลลัพธ์และรูปร่างจะเหมือนกับเวอร์ชันก่อนหน้าที่ใช้การวนซ้ำ ต่อไปนี้ `np.dot` จะถูกใช้สำหรับการดำเนินการเหล่านี้ การทำนายตอนนี้เป็นคำสั่งเดียว ฟังก์ชันส่วนใหญ่จะนำไปใช้โดยตรงแทนที่จะเรียกฟังก์ชันการทำนายแยกต่างหาก"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515430f7",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_4\"></a>\n",
    "# 4 คำนวณ cost ด้วยตัวแปรหลายตัว\n",
    "สมการสำหรับฟังก์ชันต้นทุนที่มีตัวแปรหลายตัว $J(\\mathbf{w},b)$ คือ:\n",
    "$$J(\\mathbf{w},b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})^2 \\tag{3}$$ \n",
    "โดยที่:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b  \\tag{4} $$ \n",
    "\n",
    "\n",
    "ซึ่งแตกต่างจากห้องปฏิบัติการก่อนหน้านี้, $\\mathbf{w}$ และ  $\\mathbf{x}^{(i)}$ ป็นเวกเตอร์แทนที่จะเป็นสเกลาร์ รองรับคุณลักษณะหลายตัว"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1698185",
   "metadata": {},
   "source": [
    "ด้านล่างนี้เป็นการใช้งานสมการ (3) และ (4) โปรดสังเกตว่านี่ใช้ *รูปแบบมาตรฐานสำหรับหลักสูตรนี้* ซึ่งใช้ลูป for สำหรับตัวอย่างทั้งหมด `m`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8617d9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w, b): \n",
    "    \"\"\"\n",
    "    compute cost\n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters  \n",
    "      b (scalar)       : model parameter\n",
    "      \n",
    "    Returns:\n",
    "      cost (scalar): cost\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    cost = 0.0\n",
    "    for i in range(m):                                \n",
    "        f_wb_i = np.dot(X[i], w) + b           #(n,)(n,) = scalar (see np.dot)\n",
    "        cost = cost + (f_wb_i - y[i])**2       #scalar\n",
    "    cost = cost / (2 * m)                      #scalar    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3524f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and display cost using our pre-chosen optimal parameters. \n",
    "cost = compute_cost(X_train, y_train, w_init, b_init)\n",
    "print(f'Cost at optimal w : {cost}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f4b785",
   "metadata": {},
   "source": [
    "**ผลลัพธ์ที่คาดหวัง**: ค่าใช้จ่ายที่ w ที่เหมาะสม: 1.5578904045996674e-12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d3250c",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_5\"></a>\n",
    "# 5 การไล่ระดับลงด้วยตัวแปรหลายตัว\n",
    "การไล่ระดับลงสำหรับตัวแปรหลายตัว:\n",
    "\n",
    "$$\\begin{align*} \\text{ทำซ้ำ}&\\text{ จนกระทั่งลู่เข้า:} \\; \\lbrace \\newline\\;\n",
    "& w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{5}  \\; & \\text{for j = 0..n-1}\\newline\n",
    "&b\\ \\ = b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "โดยที่, n  คือจำนวนคุณลักษณะ พารามิเตอร์ $w_j$,  $b$, จะได้รับการอัปเดตพร้อมกัน และโดยที่  \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} \\tag{6}  \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{7}\n",
    "\\end{align}\n",
    "$$\n",
    "* m คือจำนวนตัวอย่างการฝึกในชุดข้อมูล\n",
    "\n",
    "    \n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ คือการทำนายของแบบจำลอง ในขณะที่ $y^{(i)}$ คือค่าเป้าหมาย\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0600ef",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_5.1\"></a>\n",
    "## 5.1 คำนวณการไล่ระดับด้วยตัวแปรหลายตัว\n",
    "การใช้งานสำหรับการคำนวณสมการ (6) และ (7) อยู่ด้านล่าง มีหลายวิธีในการใช้งานนี้ ในเวอร์ชันนี้ มี\n",
    "\n",
    "- ลูปภายนอกสำหรับตัวอย่างทั้งหมด m ตัว. \n",
    "    - $\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}$ สำหรับตัวอย่างสามารถคำนวณได้โดยตรงและสะสม\n",
    "    - ในลูปที่สองสำหรับคุณลักษณะทั้งหมด n ตัว:\n",
    "        - $\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}$ คำนวณสำหรับแต่ละ $w_j$.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c650ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b): \n",
    "    \"\"\"\n",
    "    Computes the gradient for linear regression \n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters  \n",
    "      b (scalar)       : model parameter\n",
    "      \n",
    "    Returns:\n",
    "      dj_dw (ndarray (n,)): The gradient of the cost w.r.t. the parameters w. \n",
    "      dj_db (scalar):       The gradient of the cost w.r.t. the parameter b. \n",
    "    \"\"\"\n",
    "    m,n = X.shape           #(number of examples, number of features)\n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0.\n",
    "\n",
    "    for i in range(m):                             \n",
    "        err = (np.dot(X[i], w) + b) - y[i]   \n",
    "        for j in range(n):                         \n",
    "            dj_dw[j] = dj_dw[j] + err * X[i, j]    \n",
    "        dj_db = dj_db + err                        \n",
    "    dj_dw = dj_dw / m                                \n",
    "    dj_db = dj_db / m                                \n",
    "        \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29db7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and display gradient \n",
    "tmp_dj_db, tmp_dj_dw = compute_gradient(X_train, y_train, w_init, b_init)\n",
    "print(f'dj_db at initial w,b: {tmp_dj_db}')\n",
    "print(f'dj_dw at initial w,b: \\n {tmp_dj_dw}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22da7f1",
   "metadata": {},
   "source": [
    "**ผลลัพธ์ที่คาดหวัง:**:   \n",
    "dj_db at เริ่มต้น w,b: -1.6739251122999121e-06  \n",
    "dj_dw at เริ่มต้น w,b:   \n",
    " [-2.73e-03 -6.27e-06 -2.22e-06 -6.92e-05]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54c7fc0",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_5.2\"></a>\n",
    "## 5.2 การไล่ระดับลงด้วยตัวแปรหลายตัว\n",
    "ขั้นตอนด้านล่างนี้ใช้สมการ (5) ด้านบน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3ff3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn w and b. Updates w and b by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n))   : Data, m examples with n features\n",
    "      y (ndarray (m,))    : target values\n",
    "      w_in (ndarray (n,)) : initial model parameters  \n",
    "      b_in (scalar)       : initial model parameter\n",
    "      cost_function       : function to compute cost\n",
    "      gradient_function   : function to compute the gradient\n",
    "      alpha (float)       : Learning rate\n",
    "      num_iters (int)     : number of iterations to run gradient descent\n",
    "      \n",
    "    Returns:\n",
    "      w (ndarray (n,)) : Updated values of parameters \n",
    "      b (scalar)       : Updated value of parameter \n",
    "      \"\"\"\n",
    "    \n",
    "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
    "    J_history = []\n",
    "    w = copy.deepcopy(w_in)  #avoid modifying global w within function\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_db,dj_dw = gradient_function(X, y, w, b)   ##None\n",
    "\n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        w = w - alpha * dj_dw               ##None\n",
    "        b = b - alpha * dj_db               ##None\n",
    "      \n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            J_history.append( cost_function(X, y, w, b))\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iters / 10) == 0:\n",
    "            print(f\"Iteration {i:4d}: Cost {J_history[-1]:8.2f}   \")\n",
    "        \n",
    "    return w, b, J_history #return final w,b and J history for graphing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e28647",
   "metadata": {},
   "source": [
    "ในเซลล์ถัดไป คุณจะทดสอบการใช้งาน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf222195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters\n",
    "initial_w = np.zeros_like(w_init)\n",
    "initial_b = 0.\n",
    "# some gradient descent settings\n",
    "iterations = 1000\n",
    "alpha = 5.0e-7\n",
    "# run gradient descent \n",
    "w_final, b_final, J_hist = gradient_descent(X_train, y_train, initial_w, initial_b,\n",
    "                                                    compute_cost, compute_gradient, \n",
    "                                                    alpha, iterations)\n",
    "print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")\n",
    "m,_ = X_train.shape\n",
    "for i in range(m):\n",
    "    print(f\"prediction: {np.dot(X_train[i], w_final) + b_final:0.2f}, target value: {y_train[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b6c48f",
   "metadata": {},
   "source": [
    "**ผลลัพธ์ที่คาดหวัง:**:    \n",
    "\n",
    "- b,w พบโดยการไล่ระดับลง: -0.00,[ 0.2   0.   -0.01 -0.07]\n",
    "- การทำนาย: 426.19, ค่าเป้าหมาย: 460\n",
    "- การทำนาย: 286.17, ค่าเป้าหมาย: 232\n",
    "- การทำนาย: 171.47, ค่าเป้าหมาย: 178\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079d0a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cost versus iteration  \n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, constrained_layout=True, figsize=(12, 4))\n",
    "ax1.plot(J_hist)\n",
    "ax2.plot(100 + np.arange(len(J_hist[100:])), J_hist[100:])\n",
    "ax1.set_title(\"Cost vs. iteration\");  ax2.set_title(\"Cost vs. iteration (tail)\")\n",
    "ax1.set_ylabel('Cost')             ;  ax2.set_ylabel('Cost') \n",
    "ax1.set_xlabel('iteration step')   ;  ax2.set_xlabel('iteration step') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f393b9e8",
   "metadata": {},
   "source": [
    "ผลลัพธ์เหล่านี้ไม่น่าตื่นเต้นเลย! \n",
    "\n",
    "cost คงลดลงและการทำนายของเราไม่ค่อยแม่นยำ ห้องปฏิบัติการต่อไปจะสำรวจวิธีการปรับปรุงเรื่องนี้"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aa5ce3",
   "metadata": {},
   "source": [
    "\n",
    "<a name=\"toc_15456_6\"></a>\n",
    "# 6 ยินดีด้วย!\n",
    "ในห้องปฏิบัติการนี้ คุณได้:\n",
    "- พัฒนาขั้นตอนสำหรับการถดถอยเชิงเส้นอีกครั้ง โดยตอนนี้รองรับหลายตัวแปร\n",
    "- ใช้งานฟังก์ชัน `np.dot` ของ NumPy เพื่อเวคเตอร์ไรซ์การใช้งาน\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ddd39e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "dl_toc_settings": {
   "rndtag": "15456"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
